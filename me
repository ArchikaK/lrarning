
library(plm)
library(dplyr)
library(Hmisc)
library(data.table)
library(imputeMissings)
library(corrplot)

# 1. read raw data
ds1<-read.csv("C:\\Users\\Archika Kaushik\\Documents\\data.csv", header=TRUE)

# 2. impute the missing values  
ds<-impute(ds1,method="median/mode")

setDT(ds)[, paste('X1_', 1:5, sep="") := shift(X1, 1:5)]
setDT(ds)[, paste('X2_', 1:5, sep="") := shift(X2, 1:5)]
setDT(ds)[, paste('X3_', 1:5, sep="") := shift(X3, 1:5)]
setDT(ds)[, paste('X4_', 1:5, sep="") := shift(X4, 1:5)]
  a<-as.character(colnames(ds1))  
  for (y in 31:85)    
    for (i in c(0.1, 0.2, 0.3, 0.5, 0.7, 0.9))     
    {      
    ds1[, paste(a[y], "_", i, sep="")] <- stats::filter(x=ds1[[y]], filter = i, method = "recursive")}
    
ds[is.na(ds)] <- 0

ds<-ds[-c(1,2,3,4,5),]
  data2[is.na(data2)] <- 0  
  ds<-data2[-c(1,2,3,4,5), ]  
  ds1<-data.table(ds)
  
for (n in c(0.1, 0.2, 0.3, 0.5, 0.7, 0.9))
  for (i in 1:5)
    {
    ds[, paste("X1_", i, "_", n, sep = "")] = filter(x=ds[,2], filter=n, method="recursive")
    ds[, paste("X2_", i, "_", n, sep = "")] = filter(x=ds[,3], filter=n, method="recursive")
    ds[, paste("X3_", i, "_", n, sep = "")] = filter(x=ds[,4], filter=n, method="recursive")
    ds[, paste("X4_", i, "_", n, sep = "")] = filter(x=ds[,5], filter=n, method="recursive")
  }

attach(ds)

c<-data.frame(cor(ds))

d<-data.frame(var=rownames(c), corr=c[,1])

v<-d %>% filter(corr< -0.05) %>% arrange(corr)
 
res2<-rcorr(as.matrix(ds2))  
flattenCorrMatrix <- function(cormat, pmat) {    
  ut <- upper.tri(cormat)    
  data.frame(      
    row = rownames(cormat)[row(cormat)[ut]],      
    column = rownames(cormat)[col(cormat)[ut]],      
    cor  =(cormat)[ut],      
    p = pmat[ut]    
    )  
    }  
r <- data.frame(flattenCorrMatrix(res2$r, res2$P)) %>% filter(row=="NTB", p<0.05)     

write.csv(r, file = "MyData.csv")    
r<-r %>% arrange(r[, 'p'])

# 6. Check  of variables  

attach(data2)  
par(mfrow = c(2, 2))  
hist(X1)  
hist(X2)  
qqnorm(X1)  
qqline(X1)  
qqnorm(X2)  
qqline(X2)

# 7. Shapiro wilks test for normality
  shapiro.test(X1)

qqnorm(log(X2)) #lognormal distributuion  
qqline(log(X2), col="red")  
hist(X2)  
hist(log(X2))

# 8. stepwise vif calculation
vif_func<-function(in_frame,thresh=10,trace=T,...){    
require(fmsb)    
if(class(in_frame) != 'data.frame') in_frame<-data.frame(in_frame)    #get initial vif value for all comparisons of variables  vif_init<-NULL  var_names <- names(in_frame)  for(val in var_names){    regressors <- var_names[-which(var_names == val)]    form <- paste(regressors, collapse = '+')    form_in <- formula(paste(val, '~', form))    vif_init<-rbind(vif_init, c(val, VIF(lm(form_in, data = in_frame, ...))))  }  vif_max<-max(as.numeric(vif_init[,2]), na.rm = TRUE)    if(vif_max < thresh){    if(trace==T){ #print output of each iteration      prmatrix(vif_init,collab=c('var','vif'),rowlab=rep('',nrow(vif_init)),quote=F)      cat('\n')      cat(paste('All variables have VIF < ', thresh,', max VIF ',round(vif_max,2), sep=''),'\n\n')    }    return(var_names)  }  else{        in_dat<-in_frame        #backwards selection of explanatory variables, stops when all VIF values are below 'thresh'    while(vif_max >= thresh){            vif_vals<-NULL      var_names <- names(in_dat)            for(val in var_names){        regressors <- var_names[-which(var_names == val)]        form <- paste(regressors, collapse = '+')        form_in <- formula(paste(val, '~', form))        vif_add<-VIF(lm(form_in, data = in_dat, ...))        vif_vals<-rbind(vif_vals,c(val,vif_add))      }      max_row<-which(vif_vals[,2] == max(as.numeric(vif_vals[,2]), na.rm = TRUE))[1]            vif_max<-as.numeric(vif_vals[max_row,2])            if(vif_max<thresh) break            if(trace==T){ #print output of each iteration        prmatrix(vif_vals,collab=c('var','vif'),rowlab=rep('',nrow(vif_vals)),quote=F)        cat('\n')        cat('removed: ',vif_vals[max_row,1],vif_max,'\n\n')        flush.console()      }            in_dat<-in_dat[,!names(in_dat) %in% vif_vals[max_row,1]]          }        return(as.data.frame(names(in_dat)))      }  }
vif_func(ds2[,-c(1)],thresh=10,trace=T)#run this to drop highly correlated vars

data6<-data5[,c("X1",
                 "X2",
                 "X3")]

model2<-lm(data=data6,NTB~.)
summary(model2)

#mape calculation
resid<-as.data.frame(model2$residuals)
data_mape<-cbind(data6,resid)data_mape$resid_per<-abs(data_mape$`model2$residuals`/data_mape$NTB)sum(data_mape$resid_per)/nrow(data_mape)*100 #MAPE VALUE
